{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxh8086/PyTrade/blob/main/2022_PyAutomation_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OA8_66TiaJvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8291d71b-ce44-4c55-99b5-e1e3a8bf0549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vollib_vectorized\n",
            "  Downloading py_vollib_vectorized-0.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting py-vollib>=1.0.1\n",
            "  Downloading py_vollib-1.0.1.tar.gz (19 kB)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.7/dist-packages (from py_vollib_vectorized) (0.51.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from py_vollib_vectorized) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from py_vollib_vectorized) (1.1.5)\n",
            "Collecting py-lets-be-rational\n",
            "  Downloading py_lets_be_rational-1.0.1.tar.gz (18 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from py_vollib_vectorized) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.51.0->py_vollib_vectorized) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51.0->py_vollib_vectorized) (0.34.0)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->py_vollib_vectorized) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->py_vollib_vectorized) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->py_vollib_vectorized) (1.15.0)\n",
            "Building wheels for collected packages: py-vollib, py-lets-be-rational\n",
            "  Building wheel for py-vollib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-vollib: filename=py_vollib-1.0.1-py3-none-any.whl size=62855 sha256=8fb84e0accf1a969bcf7f1158e8ccab87a8b295ce0a5e804ea94a59587c33821\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/25/50/bc80b93c9a827ed9bef9d86f85365e1934bcbc0666b9f00c11\n",
            "  Building wheel for py-lets-be-rational (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-lets-be-rational: filename=py_lets_be_rational-1.0.1-py3-none-any.whl size=24468 sha256=e196775268216a30a3b225b2217d388cdb1f7d71cfd23f674c29dfbd64390e16\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/70/10/bf54a16badc528594c9510ef517badb765a29b651ea5652898\n",
            "Successfully built py-vollib py-lets-be-rational\n",
            "Installing collected packages: simplejson, py-lets-be-rational, py-vollib, py-vollib-vectorized\n",
            "Successfully installed py-lets-be-rational-1.0.1 py-vollib-1.0.1 py-vollib-vectorized-0.1.1 simplejson-3.17.6\n"
          ]
        }
      ],
      "source": [
        "!pip install py_vollib_vectorized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lcb3U0WZks5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f72e08-e898-4e34-d42d-b2325f11ff52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "rm: cannot remove 'eod_data.db': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/')\n",
        "!cp '/content/gdrive/MyDrive/Colab Notebooks/historicVolatility.py' . -f\n",
        "!rm 'eod_data.db'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JSAIAj_ZR0IT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aea232f-89a7-4676-fd6f-a527f571972b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-15 04:48:20 INFO: SQL DB eod_data.db created\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Import Python Library\n",
        "# import sys\n",
        "from datetime import datetime, time, timedelta, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from time import sleep\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from numpy import log\n",
        "\n",
        "import math\n",
        "import math\n",
        "from math import e\n",
        "\n",
        "import requests\n",
        "from io import StringIO\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# import pymysql\n",
        "import sqlite3\n",
        "import sqlalchemy\n",
        "from sqlalchemy import Table, Column, Float, Integer, String, MetaData, ForeignKey, create_engine\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s %(levelname)s: %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# connect mySQL DB using sqlalchemy\n",
        "# engine = sqlalchemy.create_engine('mysql+pymysql://pyadmin:pyU$er#123@127.0.0.1:3306/eod_data')\n",
        "\n",
        "# Connect Local DB File using SQLite : Connect to a DB file if it exists, else crete a new file\n",
        "db_file1 = \"eod_data.db\"\n",
        "engine = sqlite3.connect(db_file1)\n",
        "sqlite_cursor = engine.cursor()\n",
        "sqlite_cursor.close()\n",
        "engine.close()\n",
        "logging.info(f'SQL DB {db_file1} created')\n",
        "\n",
        "# # Connect mySQL DB using pymySQL coonector\n",
        "# db_connection = pymysql.connect(host='127.0.0.1', user='pyadmin', password = \"pyU$er#123\", db='eod_data',)\n",
        "\n",
        "# # Connect SQLite DB using SQLAlchemy connector\n",
        "# sqlite_engine = create_engine('sqlite:///eod_data.db')\n",
        "# pyconnector = sqlite_engine.connect()\n",
        "\n",
        "\n",
        "# # WARNING: All numbers should be floats -> x = 1.0\n",
        "from py_vollib_vectorized import price_dataframe, get_all_greeks\n",
        "from py_vollib_vectorized import vectorized_implied_volatility as iv\n",
        "\n",
        "import requests\n",
        "from io import StringIO\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Import In house Library for NSE\n",
        "from historicVolatility import get_vix, get_symbol_open_data\n",
        "\n",
        "# init all necessary variables\n",
        "today = date.today()\n",
        "symbol = 'BANKNIFTY'\n",
        "indices = 'NIFTY BANK'\n",
        "table = symbol.lower()\n",
        "EOD_DB_UPDATED = 0\n",
        "BOD_DB_UPDATED = 0\n",
        "\n",
        "# set date range for historical prices\n",
        "start_of_year = date(today.year, 1, 1)\n",
        "end_date = today  # - timedelta(days=400) # 24-03-2021\n",
        "start_date = end_date - timedelta(days=30)  # 24-03-2020\n",
        "\n",
        "# reformat date range\n",
        "def_end = end_date.strftime('%d-%b-%Y')\n",
        "def_start = start_date.strftime('%d-%b-%Y')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QvsErrEmIyqd"
      },
      "outputs": [],
      "source": [
        "def pct_change(first, second):\n",
        "    diff = second - first\n",
        "    change = 0\n",
        "    try:\n",
        "        if diff > 0:\n",
        "            change = (diff / first) * 100\n",
        "        elif diff < 0:\n",
        "            diff = first - second\n",
        "            change = -((diff / first) * 100)\n",
        "    except ZeroDivisionError:\n",
        "        return float('inf')\n",
        "    return change\n",
        "\n",
        "\n",
        "def percentage_change(col1, col2):\n",
        "    return round(((col2 - col1) / col1) * 100, 2)\n",
        "\n",
        "\n",
        "def url_to_json(url):\n",
        "    baseurl = \"https://www.nseindia.com\"\n",
        "    output = \"\"\n",
        "    newheader = {\n",
        "        'Connection': 'keep-alive',\n",
        "        'Cache-Control': 'max-age=0',\n",
        "        'DNT': '1',\n",
        "        'Upgrade-Insecure-Requests': '1',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36',\n",
        "        'Sec-Fetch-User': '?1',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "        'Sec-Fetch-Site': 'none',\n",
        "        'Sec-Fetch-Mode': 'navigate',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Accept-Language': 'en-US,en;q=0.9,hi;q=0.8',\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        output = requests.get(baseurl, headers=newheader)\n",
        "        print(output)\n",
        "        s = requests.Session()\n",
        "        output = s.get(baseurl, headers=newheader)\n",
        "        print(output)\n",
        "        output = s.get(url, headers=newheader).json()\n",
        "        print(output)\n",
        "    except ValueError as error:\n",
        "        print(error, \"error\")\n",
        "        return\n",
        "    finally:\n",
        "        return output\n",
        "\n",
        "\n",
        "def old_url_raw(url):\n",
        "    baseurl = \"https://www.nseindia.com\"\n",
        "\n",
        "    oldheader = {\n",
        "        \"Host\": \"www1.nseindia.com\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\",\n",
        "        \"Accept\": \"*/*\",\n",
        "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
        "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
        "        \"Referer\": \"https://www1.nseindia.com/products/content/equities/indices/historical_index_data.htm\",\n",
        "        \"Access-Control-Allow-Origin\": \"*\",\n",
        "        \"Access-Control-Allow-Methods\": \"GET,POST,PUT,DELETE,OPTIONS\",\n",
        "        \"Access-Control-Allow-Headers\": \"Content-Type, Access-Control-Allow-Headers, Authorization, X-Requested-With\",\n",
        "        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        output = requests.get(baseurl, headers=oldheader)\n",
        "        s = requests.Session()\n",
        "        output = s.get(baseurl, headers=oldheader)\n",
        "        output = s.get(url, headers=oldheader)\n",
        "    except ValueError as error:\n",
        "        print(error, \"error\")\n",
        "        return\n",
        "    finally:\n",
        "        return output\n",
        "\n",
        "\n",
        "def new_url_raw(url):\n",
        "    baseurl = \"https://www.nseindia.com\"\n",
        "\n",
        "    newheaders = {\n",
        "        'Connection': 'keep-alive',\n",
        "        'Cache-Control': 'max-age=0',\n",
        "        'DNT': '1',\n",
        "        'Upgrade-Insecure-Requests': '1',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36',\n",
        "        'Sec-Fetch-User': '?1',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "        'Sec-Fetch-Site': 'none',\n",
        "        'Sec-Fetch-Mode': 'navigate',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Accept-Language': 'en-US,en;q=0.9,hi;q=0.8',\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        output = requests.get(baseurl, headers=newheaders)\n",
        "        s = requests.Session()\n",
        "        output = s.get(baseurl, headers=newheaders)\n",
        "        output = s.get(url, headers=newheaders)\n",
        "    except ValueError as error:\n",
        "        print(error, \"error\")\n",
        "        return\n",
        "    except HTTPError as error:\n",
        "        print(\"Server not reachable try again after sometime\")\n",
        "        return\n",
        "    finally:\n",
        "        return output\n",
        "\n",
        "\n",
        "def option_chain(symbol):\n",
        "    URL = 'https://www.nseindia.com/api/option-chain-indices?symbol=' + symbol\n",
        "    response = url_to_json(URL)\n",
        "    return response\n",
        "\n",
        "\n",
        "def get_online_db(indices=indices, sdt=def_start, edt=def_end):\n",
        "    indicsurl = \"https://www1.nseindia.com/products/dynaContent/equities/indices/historicalindices.jsp?indexType=\" + indices + \"&fromDate=\" + sdt + \"&toDate=\" + edt\n",
        "    while True:\n",
        "        try:\n",
        "            response = old_url_raw(indicsurl)\n",
        "        except exception:\n",
        "            print('unable to update historical data')\n",
        "            return\n",
        "        finally:\n",
        "            if response.status_code == 200:\n",
        "                page_content = BeautifulSoup(response.content, \"html.parser\")\n",
        "                try:\n",
        "                    strings = page_content.find(id=\"csvContentDiv\").get_text().replace(':', \"\\n\")\n",
        "                    strings = strings.replace(' ', '')\n",
        "                    pdfo = pd.read_csv(StringIO(strings), header=0)\n",
        "                    pdfo['Open'] = pdfo['Open'].replace('-', np.nan).fillna(pdfo.Close).astype(float).round(2)\n",
        "                    pdfo['High'] = pdfo['High'].replace('-', np.nan).fillna(pdfo.Close).astype(float).round(2)\n",
        "                    pdfo['Low'] = pdfo['Low'].replace('-', np.nan).fillna(pdfo.Close).astype(float).round(2)\n",
        "                    pdfo['SharesTraded'] = pdfo['SharesTraded'].replace('-', '0')\n",
        "                    pdfo['Turnover(Rs.Cr)'] = pdfo['Turnover(Rs.Cr)'].replace('-', '0')\n",
        "                    pdfo['Date'] = pd.to_datetime(pdfo['Date']).dt.strftime('%Y-%m-%d').astype(str)\n",
        "                    # print(df)\n",
        "                except AttributeError as e:\n",
        "                    return\n",
        "            else:\n",
        "                response.raise_for_status()\n",
        "        break\n",
        "    return pdfo\n",
        "\n",
        "def nearest(datelist, pivot=today):\n",
        "    items = [datetime.strptime(d, '%d-%b-%Y').date() for d in datelist]\n",
        "    return min(items, key=lambda x: abs(x - pivot)).strftime('%d-%b-%Y')\n",
        "\n",
        "\n",
        "def get_nearest(strike_data, lastprice):\n",
        "    price_array = []\n",
        "    first_ce = 0\n",
        "    first_pe = 0\n",
        "    second_ce = 0\n",
        "    second_pe = 0\n",
        "    for i in strike_data:\n",
        "        price_array.append([round(abs(lastprice - i), 2), i])\n",
        "    strike_list = sorted(price_array)\n",
        "    if strike_list[0][1] > lastprice:\n",
        "        first_ce = strike_list[0][1]\n",
        "        first_pe = strike_list[1][1]\n",
        "    if strike_list[1][1] > lastprice:\n",
        "        first_ce = strike_list[1][1]\n",
        "        first_pe = strike_list[0][1]\n",
        "    if strike_list[2][1] > lastprice:\n",
        "        second_ce = strike_list[2][1]\n",
        "        second_pe = strike_list[3][1]\n",
        "    if strike_list[3][1] > lastprice:\n",
        "        second_ce = strike_list[3][1]\n",
        "        second_pe = strike_list[2][1]\n",
        "    return first_ce, first_pe, second_ce, second_pe\n",
        "\n",
        "\n",
        "def total_loss_at_strike(chain, expiry_price):\n",
        "    # \"\"\"Calculate loss at strike price\"\"\"\n",
        "    # All call options with strike price below the expiry price will result in loss for option writers\n",
        "    in_money_calls = chain[chain['strikePrice'] < expiry_price][[\"oI_ce\", \"strikePrice\"]]\n",
        "    in_money_calls[\"CE loss\"] = (expiry_price - in_money_calls['strikePrice']) * in_money_calls[\"oI_ce\"]\n",
        "\n",
        "    # All put options with strike price above the expiry price will result in loss for option writers\n",
        "    in_money_puts = chain[chain['strikePrice'] > expiry_price][[\"oI_pe\", \"strikePrice\"]]\n",
        "    in_money_puts[\"PE loss\"] = (in_money_puts['strikePrice'] - expiry_price) * in_money_puts[\"oI_pe\"]\n",
        "    total_loss = in_money_calls[\"CE loss\"].sum() + in_money_puts[\"PE loss\"].sum()\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def geeks_calc(oiraw):\n",
        "    geeks_list = []\n",
        "    #Interest Rate is defined as per NSE Option IV Calculation document. \n",
        "    # NSE is using 10% interest as default interest rate for Black Scholes Model IV calculation for Option Chain\n",
        "    int_rate = float(10 /100)\n",
        "    oiraw['expiryDate'] = pd.to_datetime(oiraw['expiryDate'], format =  '%d-%b-%Y')\n",
        "    # print(underlaying,expiry,strike,itype,ltp)\n",
        "    FMT = '%H:%M:%S'\n",
        "    s1 = datetime.now().strftime(FMT)\n",
        "    s2 = '15:30:00'  # Expiry End\n",
        "    tdelta = datetime.strptime(s2, FMT) - datetime.strptime(s1, FMT)\n",
        "    timeleft = (tdelta.seconds / 86400)\n",
        "    oiraw['tte'] = ((oiraw['expiryDate']-pd.Timestamp(date.today())).dt.days + timeleft) / 365\n",
        "    oiraw['int'] = int_rate\n",
        "    oiraw['underlyingValue'] = oiraw['underlyingValue'].astype(float)\n",
        "    oiraw['strikePrice'] = oiraw['strikePrice'].astype(float)\n",
        "    oiraw['ltP'] = oiraw['ltP'].astype(float)\n",
        "    oiraw['tte'] = oiraw['tte'].astype(float)\n",
        "    oiraw['Flag'] = oiraw['type'].str[0].str.lower()\n",
        "    StrikePrice = oiraw['underlyingValue'][0]\n",
        "    oiraw = oiraw.drop(oiraw[(oiraw['Flag'] == 'ce') & (oiraw['strikePrice'] < StrikePrice) ].index, inplace=False)\n",
        "    oiraw = oiraw.drop(oiraw[(oiraw['Flag'] == 'pe') & (oiraw['strikePrice'] > StrikePrice) ].index, inplace=False)\n",
        "    # print(oiraw)\n",
        "    # py_vollib_vectorized.implied_volatility.vectorized_implied_volatility(price, S, K, t, r, flag, q=None, *, on_error='warn',\n",
        "    #                                    model='black_scholes', return_as='dataframe', dtype=<class 'numpy.float64'>, **kwargs)\n",
        "    # price_dataframe(df, flag_col='Flag', underlying_price_col='S', strike_col='K', annualized_tte_col='T',\n",
        "    #                 riskfree_rate_col='R', price_col='LTP', model='black_scholes', inplace=False)\n",
        "    return price_dataframe(oiraw, flag_col='Flag', underlying_price_col='underlyingValue', strike_col='strikePrice', annualized_tte_col='tte',\n",
        "                     riskfree_rate_col='int', price_col='ltP', model='black_scholes', inplace=False)\n",
        "\n",
        "\n",
        "def consolidated(nearmonth, expiryDates):\n",
        "    items = [datetime.strptime(d, '%d-%b-%Y').date() for d in expiryDates]\n",
        "    nearlist1 = []\n",
        "    nearlist2 = []\n",
        "    for r in range(4):\n",
        "        a = list(filter(lambda d: (d.month == today.month + r), items))\n",
        "        if len(a) > 0:\n",
        "            if 0 < r < 3:\n",
        "                nearlist1.append(max(a).strftime('%d-%b-%Y'))\n",
        "            else:\n",
        "                for i in a:\n",
        "                    nearlist1.append(i.strftime('%d-%b-%Y'))\n",
        "            if 1 < r:\n",
        "                nearlist2.append(max(a).strftime('%d-%b-%Y'))\n",
        "            else:\n",
        "                for i in a:\n",
        "                    nearlist2.append(i.strftime('%d-%b-%Y'))\n",
        "    return nearlist1 if nearlist1 [0] != nearmonth else nearlist2\n",
        "\n",
        "\n",
        "def fetchExpiry(datelist):\n",
        "    print('categorising expiry dates')\n",
        "    s = pd.Series(pd.to_datetime(datelist))\n",
        "    monthly = s.groupby(s.dt.strftime('%Y-%m')).max().dt.strftime('%d-%b-%Y').tolist()\n",
        "    weekly = list(set(datelist) - set(monthly))\n",
        "    current = nearest(datelist)\n",
        "    nearmonth = nearest(monthly)\n",
        "    extracted = consolidated(nearmonth, datelist)\n",
        "    return current, nearmonth, weekly, monthly, extracted\n",
        "\n",
        "\n",
        "def get_db(table=table, std=def_start, edt=def_end, update=None):\n",
        "    if table != \"bod_data\":\n",
        "        # init required variables\n",
        "        df = pd.DataFrame()\n",
        "        if update is None:\n",
        "            std = datetime.strptime(std, '%d-%b-%Y').strftime('%Y-%m-%d')\n",
        "            etd = datetime.strptime(ed8t, '%d-%b-%Y').strftime('%Y-%m-%d')\n",
        "            myQuery = '''\n",
        "                     SELECT * \n",
        "                     FROM {0} \n",
        "                     WHERE Date BETWEEN '{1}' AND '{2}' \n",
        "                     ORDER BY Date DESC\n",
        "                     ;'''.format(table, std, etd)\n",
        "        elif update == 'lastline':\n",
        "            myQuery = '''\n",
        "                     SELECT * \n",
        "                     FROM {0}\n",
        "                     ORDER BY Date DESC\n",
        "                     Limit 1\n",
        "                     ;'''.format(table)\n",
        "        else:\n",
        "            myQuery = '''SELECT * FROM {0};'''.format(table)\n",
        "\n",
        "        try:\n",
        "            engine = sqlite3.connect(db_file1)\n",
        "            df = pd.read_sql_query(myQuery, engine, coerce_float=False)\n",
        "        finally:\n",
        "            engine.close()\n",
        "            return df\n",
        "    else:\n",
        "        # init required variables\n",
        "        df = pd.DataFrame()\n",
        "        myQuery = '''SELECT * FROM {0};'''.format(table)\n",
        "        try:\n",
        "            engine = sqlite3.connect(db_file1)\n",
        "            df = pd.read_sql_query(myQuery, engine, coerce_float=False)\n",
        "        finally:\n",
        "            engine.close()\n",
        "            return df\n",
        "\n",
        "\n",
        "def df_to_sql(df, table, db):\n",
        "    # df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d').astype(str)\n",
        "    print(df.dtypes)\n",
        "    # To connect MySQL database\n",
        "    # Connect mySQL DB using pymySQL coonector\n",
        "    # db_connection = pymysql.connect(host='127.0.0.1', user='pyadmin', password=\"pyU$er#123\", db='eod_data', )\n",
        "\n",
        "    # Connect Local SQLite DB using sqlite3 coonector\n",
        "    engine = sqlite3.connect(db_file1)\n",
        "    # MySQL Query to alter Table Format\n",
        "    # updatequery = ('''\n",
        "    #               ALTER TABLE {0}\n",
        "    #               CHANGE COLUMN `Date` `Date` DATE NOT NULL ,\n",
        "    #               ADD PRIMARY KEY (`Date`),\n",
        "    #               ''').format(table)\n",
        "    if db == \"eod_data\":\n",
        "        try:\n",
        "            # print(df)\n",
        "            # Update DB to SQLite\n",
        "            df.to_sql(name=table, con=engine, index=False, if_exists='replace')\n",
        "            # Update DB to MySQL\n",
        "            #df.to_sql(name=table, con=engine, index=True, if_exists='replace',\n",
        "            #          dtype={'Date': sqlalchemy.types.TEXT(),\n",
        "            #                 'Open': sqlalchemy.types.Float(),\n",
        "            #                 'High': sqlalchemy.types.Float(),\n",
        "            #                 'Low': sqlalchemy.types.Float(),\n",
        "            #                 'Close': sqlalchemy.types.Float(),\n",
        "            #                 'NaturalLog': sqlalchemy.types.Float(),\n",
        "            #                 'StdDev': sqlalchemy.types.Float(),\n",
        "            #                 'W_HV': sqlalchemy.types.Float(),\n",
        "            #                 'M_HV': sqlalchemy.types.Float(),\n",
        "            #                 'Y_HV': sqlalchemy.types.Float(),\n",
        "            #                 'SharesTraded': sqlalchemy.types.Float(),\n",
        "            #                 'Turnover(Rs.Cr)': sqlalchemy.types.Float()\n",
        "            #                 })\n",
        "            # Update  / alter Database Schema to default (Supported only in MySQL not in SQLite)\n",
        "            print('Backfill completed(DF to SQL)')\n",
        "\n",
        "        finally:\n",
        "            # To close the connection\n",
        "            engine.close()\n",
        "    elif db == \"bod_data\":\n",
        "        try:\n",
        "            # Update DB to SQLite\n",
        "            df.to_sql(name=table, con=engine, index=False, if_exists='replace')\n",
        "            # Update DB to MySQL\n",
        "            #df.to_sql(name=table, con=engine, index=True, if_exists='replace',\n",
        "            #          dtype={'Date': sqlalchemy.types.TEXT(),\n",
        "            #                 'symbol': sqlalchemy.types.VARCHAR(20),\n",
        "            #                 'Open': sqlalchemy.types.Float(precision=2),\n",
        "            #                 'previousClose': sqlalchemy.types.Float(precision=2),\n",
        "            #                 'pChange': sqlalchemy.types.Float(precision=2)\n",
        "            #                 })\n",
        "        finally:\n",
        "            engine.close()\n",
        "            print('BOD Data Updated')\n",
        "\n",
        "\n",
        "def update_db(table=table, indices=indices, std=def_start, edt=def_end):\n",
        "    # get online data to process and update\n",
        "    try:\n",
        "        online = get_online_db(indices, std, edt)\n",
        "    except exception:\n",
        "        print('issue while fetching online data')\n",
        "        online = pd.DataFrame()\n",
        "        return online\n",
        "    finally:\n",
        "        # get offline data to process and update\n",
        "        offline = get_db(table, None, None, True)\n",
        "\n",
        "        merged = pd.concat([online, offline])\n",
        "        merged['Date'] = pd.to_datetime(merged['Date']).dt.strftime('%Y-%m-%d').astype(str)\n",
        "        merged = merged.drop_duplicates(subset=['Date'])\n",
        "        merged = merged.sort_values(by='Date', ascending=True)\n",
        "        merged['NaturalLog'] = merged['NaturalLog'].fillna(0).astype(float).round(6)\n",
        "        merged['StdDev'] = merged['StdDev'].fillna(0).astype(float).round(6)\n",
        "        merged['W_HV'] = merged['W_HV'].fillna(0).astype(float).round(6)\n",
        "        merged['M_HV'] = merged['M_HV'].fillna(0).astype(float).round(6)\n",
        "        merged['Y_HV'] = merged['Y_HV'].fillna(0).astype(float).round(6)\n",
        "        merged['NaturalLog'] = np.log(merged.Close / merged.Close.shift(-1)).shift(1)\n",
        "        merged['StdDev'] = merged['NaturalLog'].rolling(252).std().fillna(0).astype(float).round(6)\n",
        "        merged['W_HV'] = round(merged['StdDev'] * math.sqrt(5), 2)\n",
        "        merged['M_HV'] = round(merged['StdDev'] * math.sqrt(22), 2)\n",
        "        merged['Y_HV'] = round(merged['StdDev'] * math.sqrt(252), 2)\n",
        "        # print(merged.tail(50))\n",
        "\n",
        "        # Update data to DB\n",
        "        df_to_sql(merged, table, 'eod_data')\n",
        "\n",
        "\n",
        "def eod_backfill(indices, table=table):\n",
        "    # Initialize required variables\n",
        "    prices = pd.DataFrame()\n",
        "    inityear = 2000\n",
        "    initdate = date(inityear, 1, 1)\n",
        "    year_range = relativedelta(today, initdate)\n",
        "\n",
        "    for i in range(year_range.years):\n",
        "        st1 = (date(inityear, 1, 1) + relativedelta(years=i)).strftime(\"%d-%m-%Y\")\n",
        "        ed1 = (date(inityear, 11, 30) + relativedelta(years=i)).strftime(\"%d-%m-%Y\")\n",
        "        prices = prices.append(get_online_db(indices, st1, ed1))\n",
        "        st2 = (date(inityear, 12, 1) + relativedelta(years=i)).strftime(\"%d-%m-%Y\")\n",
        "        ed2 = (date(inityear, 12, 31) + relativedelta(years=i)).strftime(\"%d-%m-%Y\")\n",
        "        prices = prices.append(get_online_db(indices, st2, ed2))\n",
        "        print('initiating backfill for period:', st1, ' to ', ed2)\n",
        "    st3 = date(today.year, 1, 1).strftime(\"%d-%m-%Y\")\n",
        "    ed3 = today.strftime(\"%d-%m-%Y\")\n",
        "    print('initiating backfill for period:', st3, ' to ', ed3)\n",
        "    prices = prices.append(get_online_db(indices, st3, ed3))\n",
        "    # print(prices)\n",
        "    prices ['Date'] = pd.to_datetime(prices ['Date']).dt.strftime('%Y-%m-%d').astype(str)\n",
        "    prices = prices.drop_duplicates(subset=['Date'])\n",
        "    prices ['NaturalLog'] = np.log(prices.Close / prices.Close.shift(-1)).shift(1).fillna(0).astype(float).round(6)\n",
        "    prices ['StdDev'] = prices ['NaturalLog'].rolling(252).std().fillna(0).astype(float).round(6)\n",
        "    prices ['W_HV'] = round(prices ['StdDev'] * math.sqrt(5) * 100, 2)\n",
        "    prices ['M_HV'] = round(prices ['StdDev'] * math.sqrt(22) * 100, 2)\n",
        "    prices ['Y_HV'] = round(prices ['StdDev'] * math.sqrt(252) * 100, 2)\n",
        "    df_to_sql(prices, table, 'eod_data')\n",
        "\n",
        "\n",
        "def drop_table(table):\n",
        "    print('need to drop table {}'.format(table))\n",
        "    # Connect mySQL DB using pymySQL coonector\n",
        "    # db_connection = pymysql.connect(host='127.0.0.1', user='pyadmin', password=\"pyU$er#123\", db='eod_data', )\n",
        "    engine = sqlite3.connect(db_file1)\n",
        "    sqlite_cursor = db_connection.cursor()\n",
        "    dropquery = ('''DROP TABLE IF EXISTS {0} ;''').format(table)\n",
        "    output = sqlite_cursor.execute(dropquery)\n",
        "    # To close the connection\n",
        "    sqlite_cursor.close()\n",
        "    engine.close()\n",
        "    return output\n",
        "\n",
        "\n",
        "def request_eod(table):\n",
        "    print('checking for eod data')\n",
        "    output = ''\n",
        "    # engine = pymysql.connect(host='127.0.0.1', user='pyadmin', password=\"pyU$er#123\", db='eod_data', )\n",
        "    engine = sqlite3.connect(db_file1)\n",
        "    cursor1 = engine.cursor()\n",
        "    cursor2 = engine.cursor()\n",
        "    queryrow = 'SELECT COUNT(*) FROM {0};'.format(table)\n",
        "    updatequery = ('''SELECT * FROM {0} ORDER BY Date DESC Limit 1;''').format(table)\n",
        "    try:\n",
        "        # Connect mySQL DB using pymySQL coonector\n",
        "        cursor1.execute(updatequery)\n",
        "        output = cursor1.fetchone()\n",
        "        cursor2.execute(queryrow)\n",
        "        rowcount = cursor2.fetchall()[0][0]\n",
        "    #except pymysql.ProgrammingError as e:\n",
        "    #    if (e.args [0] == 1146):\n",
        "    #        print(\"Table dosen't exist, need to backfill\")\n",
        "    #        output = None\n",
        "    except sqlite3.OperationalError as e:\n",
        "        print(\"Table dosen't exist, need to backfill\")\n",
        "        output = None\n",
        "    finally:\n",
        "        # To close the connection\n",
        "        cursor1.close()\n",
        "        cursor2.close()\n",
        "        engine.close()\n",
        "        if output is not None:\n",
        "          last_date = datetime.strptime(output[0],'%Y-%m-%d').date()\n",
        "        \n",
        "        if output is None:\n",
        "            print('initiated complete backfill')\n",
        "            eod_backfill(indices, table)\n",
        "        elif last_date < start_of_year:\n",
        "            print('Dropped old table and initiated complete backfill')\n",
        "            drop_table(table)\n",
        "            eod_backfill(indices, table)\n",
        "        elif last_date <= (today - timedelta(days=30)) and last_date >= start_of_year:\n",
        "            print('initiated full year backfill')\n",
        "            beganing_year = start_of_year.strftime('%d-%m-%Y')\n",
        "            update_db(table, indices, beganing_year, def_end)\n",
        "        elif 0 < today.weekday() < 5 and last_date != today and rowcount > 252:\n",
        "            print('initiated backfill for weekdays')\n",
        "            update_db(table, indices, def_start, def_end)\n",
        "        elif today.weekday() == 5 and last_date != (today - timedelta(days=1)) and rowcount > 252:\n",
        "            print('initiated backfill over weekend')\n",
        "            update_db(table, indices, def_start, def_end)\n",
        "        elif today.weekday() == 6 and last_date != (today - timedelta(days=2)) and rowcount > 252:\n",
        "            print('initiated backfill over weekend')\n",
        "            update_db(table, indices, def_start, def_end)\n",
        "        elif today.weekday() == 0 and last_date != (today - timedelta(days=3)) and rowcount > 252:\n",
        "            print('initiated for weekend')\n",
        "            update_db(table, indices, def_start, def_end)\n",
        "        else:\n",
        "            return get_db(table, update='lastline').iloc[0]\n",
        "\n",
        "    return get_db(table, update='lastline').iloc[0]\n",
        "\n",
        "\n",
        "def get_bod_online(symbol):\n",
        "    if symbol == 'BANKNIFTY':\n",
        "        indices = 'NIFTY BANK'\n",
        "    elif symbol == 'NIFTY':\n",
        "        indices = 'NIFTY 50'\n",
        "    else:\n",
        "        indices = symbol\n",
        "    table = \"bod_data\"\n",
        "    indicsOHLCurl = \"https://www.nseindia.com/api/equity-stockIndices?index=\" + indices\n",
        "    json_data = url_to_json(indicsOHLCurl)\n",
        "    # print(json_data)\n",
        "    result = [i for i in json_data ['data'] if indices in i ['symbol']]\n",
        "    bod_df = pd.DataFrame(json_data ['data'], columns=['symbol', 'open', 'previousClose'])\n",
        "    bod_df.insert(loc=0, column='Date', value=today)\n",
        "    bod_df ['pChange'] = percentage_change(bod_df ['previousClose'], bod_df ['open'])\n",
        "    df_to_sql(bod_df, table, table)\n",
        "    return 1\n",
        "\n",
        "\n",
        "def request_bod(symbol):\n",
        "    print('fetching BOD data')\n",
        "    output = ''\n",
        "    table = \"bod_data\"\n",
        "    # db_connection = pymysql.connect(host='127.0.0.1', user='pyadmin', password=\"pyU$er#123\", db='eod_data', )\n",
        "    db_connection = sqlite3.connect(db_file1)\n",
        "    cursor = db_connection.cursor()\n",
        "    updatequery = ('''SELECT * FROM {0};''').format(table)\n",
        "    try:\n",
        "        # Connect mySQL DB using pymySQL coonector\n",
        "        cursor.execute(updatequery)\n",
        "        output = cursor.fetchone()\n",
        "    # except pymysql.ProgrammingError as e:\n",
        "    #    if (e.args [0] == 1146):\n",
        "    #        print(\"Table dosen't exist, need to backfill\")\n",
        "    #        output = None\n",
        "    except sqlite3.OperationalError as e:\n",
        "        print(e)\n",
        "        output = None\n",
        "\n",
        "    finally:\n",
        "        # To close the connection\n",
        "        cursor.close()\n",
        "        db_connection.close()\n",
        "\n",
        "        if output is None:\n",
        "            print('checking bod online')\n",
        "            get_bod_online(symbol)\n",
        "            return get_db(table)\n",
        "        elif output[0] != today and today.weekday() < 5:\n",
        "            print('updating bod for today')\n",
        "            get_bod_online(symbol)\n",
        "            return get_db(table)\n",
        "        elif output[0] == today or today.weekday() >= 5:\n",
        "            return get_db(table)\n",
        "\n",
        "def update_expiry(symbol):\n",
        "    print('need to update expiry dates from online data')\n",
        "    expiryDates = option_chain(symbol)['records']['expiryDates']\n",
        "    print(expiryDates)\n",
        "    nearestwExpiry, nearmonthExpiry, wExpiry, mExpiry, consolidated = fetchExpiry(expiryDates)\n",
        "    expiryDf = pd.DataFrame()\n",
        "    eDf1 = pd.DataFrame()\n",
        "    eDf2 = pd.DataFrame()\n",
        "    eDf3 = pd.DataFrame()\n",
        "    eDf1 = eDf1.assign(mExpiry=mExpiry)\n",
        "    eDf2 = eDf2.assign(wExpiry=wExpiry)\n",
        "    eDf3 = eDf3.assign(consolidated=consolidated)\n",
        "    expiryDf = pd.concat([eDf1, eDf2, eDf3], axis=1)\n",
        "    expiryDf.loc[0, 'nearestwExpiry'] = nearestwExpiry\n",
        "    expiryDf.loc[0, 'nearmonthExpiry'] = nearmonthExpiry\n",
        "    # Update Dataframe to Table in SQLite Database\n",
        "    engine = sqlite3.connect(db_file1)\n",
        "    expiryDf.to_sql(name='expiry', con=engine, index=False, if_exists='replace')\n",
        "    # Update Dataframe to Table in MySQL Database\n",
        "    # expiryDf.to_sql(name='expiry', con=engine, index=False, if_exists='replace',\n",
        "    #                dtype={'nearestwExpiry': sqlalchemy.types.NVARCHAR(25),\n",
        "    #                       'nearmonthExpiry': sqlalchemy.types.NVARCHAR(25),\n",
        "    #                       'consolidated': sqlalchemy.types.NVARCHAR(25),\n",
        "    #                       'wExpiry': sqlalchemy.types.NVARCHAR(25),\n",
        "    #                       'mExpiry': sqlalchemy.types.NVARCHAR(25)\n",
        "    #                       })\n",
        "    engine.close()\n",
        "    return expiryDf\n",
        "\n",
        "\n",
        "def expiry_db():\n",
        "    print('getting expiry status')\n",
        "    myQuery = '''SELECT * FROM {0};'''.format('expiry')\n",
        "    engine = sqlite3.connect(db_file1)\n",
        "    expirydb = pd.read_sql_query(myQuery, engine, coerce_float=False)\n",
        "    # print(expiryDf)\n",
        "    if expirydb['nearestwExpiry'][0] < today.strftime('%d-%b-%Y'):\n",
        "        print('need to update expiry db list to latest')\n",
        "        updatedb_response = update_expiry()\n",
        "        if updatedb_response:\n",
        "            updated_expirydb = pd.read_sql_query(myQuery, engine, coerce_float=False)\n",
        "            print('updated offline expiry db')\n",
        "            engine.close()\n",
        "            return updated_expirydb\n",
        "    else:\n",
        "        print('fetched offline expiry db')\n",
        "        engine.close()\n",
        "        return expirydb\n",
        "\n",
        "\n",
        "def fno_status(symbol):\n",
        "    openInterest = 0\n",
        "    changeinOpenInterest = 0\n",
        "    url = \"https://www.nseindia.com/api/quote-derivative?symbol=\" + symbol\n",
        "    response = url_to_json(url)\n",
        "    mexpiry = expiry_db()['nearmonthExpiry'] [0]\n",
        "    for key in response['stocks']:\n",
        "        if key['metadata']['instrumentType'] == 'Index Futures':\n",
        "            openInterest += key['marketDeptOrderBook']['tradeInfo']['openInterest']\n",
        "            changeinOpenInterest += key['marketDeptOrderBook']['tradeInfo']['changeinOpenInterest']\n",
        "            if key['metadata']['expiryDate'] == mexpiry:\n",
        "                value = key['metadata']\n",
        "                fOpen = value['openPrice'];\n",
        "                fPrevClose = value['prevClose'];\n",
        "                fLtp = value['lastPrice']\n",
        "    return fOpen, fPrevClose, fLtp, openInterest, changeinOpenInterest\n",
        "\n",
        "\n",
        "#     return  {'Open': fOpen, 'PrevClose' : fPrevClose, 'ltp' : fLtp, 'OpenInterest' : openInterest, 'changeinOpenInterest': changeinOpenInterest}\n",
        "\n",
        "\n",
        "def fetch_oi(symbol):\n",
        "    geeks = ''\n",
        "    table = symbol.lower() + '_oidata_live'\n",
        "    tries = 1\n",
        "    max_retries = 3\n",
        "    while tries <= max_retries:\n",
        "        try:\n",
        "            print('calling option chain')\n",
        "            raw_oi = option_chain(symbol)\n",
        "            ce_values = [data[\"CE\"] for data in raw_oi['records']['data'] if \"CE\" in data]\n",
        "            pe_values = [data[\"PE\"] for data in raw_oi['records']['data'] if \"PE\" in data]\n",
        "            ce_data = pd.DataFrame(ce_values)\n",
        "            pe_data = pd.DataFrame(pe_values)\n",
        "            ce_data['type'] = \"CE\"\n",
        "            pe_data['type'] = \"PE\"\n",
        "            oidata = pd.concat([ce_data, pe_data])\n",
        "            print(\"getting expiry date's\")\n",
        "            expirydb = expiry_db()\n",
        "            wExpiry = expirydb['wExpiry']\n",
        "            mExpiry = expirydb['mExpiry']\n",
        "            oidata.loc[oidata['expiryDate'].isin(wExpiry), 'expiryType'] = 'w'\n",
        "            oidata.loc[oidata['expiryDate'].isin(mExpiry), 'expiryType'] = 'm'\n",
        "            oidata = oidata.drop(\n",
        "                ['askPrice', 'askQty', 'bidQty', 'bidprice', 'totalTradedVolume', 'totalBuyQuantity', 'totalSellQuantity',\n",
        "                 'underlying'], axis=1)\n",
        "            oidata.columns = ['strikePrice', 'expiryDate', 'identifier', 'OI', 'OIChange', 'pOIChange', 'iV', 'ltP', 'change',\n",
        "                              'pChange', 'underlyingValue', 'type', 'expiryType']\n",
        "            oidata = oidata.sort_values(['expiryDate', 'strikePrice'], ascending=[True, False])\n",
        "            # oidata['TimeStamp'] = datetime.now().strftime(\"%Y-%m-%d, %H:%M\")\n",
        "            _, O, H, L, C, SharesTraded, Turnover, _, DHV, WHV, MHV, YHV = request_eod(table)\n",
        "            print('calculating option geeks')\n",
        "            geeks = geeks_calc(oidata)\n",
        "            # Reformat expiry date and strike price post geeks calculation\n",
        "            oidata['expiryDate'] = oidata['expiryDate'].dt.strftime('%d-%b-%Y')\n",
        "            oidata['strikePrice'] = oidata['strikePrice'].astype(int)\n",
        "            oidata_table = pd.concat([oidata, geeks], axis=1)\n",
        "            oidata_table['IV'] = round(oidata_table['IV'], 4)\n",
        "            oidata_table ['delta'] = round(oidata_table ['delta'], 6)\n",
        "            oidata_table ['gamma'] = round(oidata_table ['gamma'], 6)\n",
        "            oidata_table ['theta'] = round(oidata_table ['theta'], 6)\n",
        "            oidata_table ['vega'] = round(oidata_table ['vega'], 6)\n",
        "            oidata_table ['rho'] = round(oidata_table ['rho'], 6)\n",
        "            oidata_table = oidata_table.drop(['int', 'Flag'], axis=1)\n",
        "            # return oidata_table\n",
        "            if not oidata_table.empty:\n",
        "                # oidata_table['I-V'] = oidata_table['I-V'].replace(to_replace=0, method='bfill').values\n",
        "                # oidata_table['TimeStamp'] = datetime.now().strftime(\"%Y-%m-%d, %H:%M\")\n",
        "                oidata_table['TimeStamp'] = datetime.now()\n",
        "                oidata_table['iV'] = oidata_table['iV'].replace(to_replace=0, method='bfill').values\n",
        "                # Update DB to SQLite\n",
        "                engine = sqlite3.connect(db_file1)\n",
        "                cursor = engine.cursor()\n",
        "                schema = '''CREATE TABLE IF NOT EXISTS {0} (\n",
        "                             ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                             TimeStamp VARCHAR(50),\n",
        "                             strikePrice VARCHAR(25),\n",
        "                             identifier VARCHAR(50),\n",
        "                             expiryDate VARCHAR(25),\n",
        "                             OI Integer(),\n",
        "                             OIChange Float(),\n",
        "                             pOIChange Float(),\n",
        "                             iV Integer(),\n",
        "                             ltP Float(),\n",
        "                             delta Float(),\n",
        "                             gamma Float(),\n",
        "                             theta Float(),\n",
        "                             vega Float(),\n",
        "                             rho Float(),\n",
        "                             tte Float(),\n",
        "                             change Integer(),\n",
        "                             pChange Float(),\n",
        "                             underlyingValue Float(),\n",
        "                             expiryType VARCHAR(2)\n",
        "                          );'''.format('expiry')\n",
        "                cursor.execute(schema)\n",
        "                cursor.commit()\n",
        "                oidata_table.to_sql(name=table, con=engine, index=False, if_exists='append')\n",
        "                # Update DB to MySQL\n",
        "                # oidata_table.to_sql(name=table, con=engine, index=False, if_exists='append',\n",
        "                #              dtype={'TimeStamp': sqlalchemy.types.TIMESTAMP(timezone=False),\n",
        "                #                     'strikePrice': sqlalchemy.types.VARCHAR(25),\n",
        "                #                     'identifier': sqlalchemy.types.VARCHAR(50),\n",
        "                #                     'expiryDate': sqlalchemy.types.VARCHAR(25),\n",
        "                #                     'OI': sqlalchemy.types.Integer(),\n",
        "                #                     'OIChange': sqlalchemy.types.Float(),\n",
        "                #                     'pOIChange': sqlalchemy.types.Float(),\n",
        "                #                     'iV': sqlalchemy.types.Integer(),\n",
        "                #                     'ltP': sqlalchemy.types.Float(),\n",
        "                #                     'delta': sqlalchemy.types.Float(),\n",
        "                #                     'gamma': sqlalchemy.types.Float(),\n",
        "                #                     'theta': sqlalchemy.types.Float(),\n",
        "                #                     'vega': sqlalchemy.types.Float(),\n",
        "                #                     'rho': sqlalchemy.types.Float(),\n",
        "                #                     'tte': sqlalchemy.types.Float(),\n",
        "                #                     'change': sqlalchemy.types.Integer(),\n",
        "                #                     'pChange': sqlalchemy.types.Float(),\n",
        "                #                     'underlyingValue': sqlalchemy.types.Float(),\n",
        "                #                     'expiryType': sqlalchemy.types.VARCHAR(2)\n",
        "                #                     })\n",
        "                engine.close()\n",
        "                return True\n",
        "\n",
        "        except Exception as error:\n",
        "            print(\"error {0}\".format(error))\n",
        "            tries += 1\n",
        "            sleep(10)\n",
        "            continue\n",
        "\n",
        "    if tries >= max_retries:\n",
        "        print(\"max retries exceeded, no new data at {0}\".format(datetime.now()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgTbPXYlaDhi"
      },
      "outputs": [],
      "source": [
        "# print(symbol)\n",
        "# print(option_chain(symbol))\n",
        "# update_expiry(symbol)\n",
        "# expiry_db()\n",
        "# request_bod(symbol)\n",
        "# fetch_oi(symbol)\n",
        "URL = 'https://www.nseindia.com/api/option-chain-indices?symbol=' + symbol\n",
        "print(url_to_json(URL))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilewW_r-SUNx"
      },
      "outputs": [],
      "source": [
        "# def main():\n",
        "#     update_expiry(symbol)\n",
        "#     request_bod(symbol)\n",
        "#     timeframe = 1\n",
        "#     slots = list(np.arange(0.0, 60.0))\n",
        "#     while time(9, 16) > datetime.now().time() >= time(00, 00):\n",
        "#         timenow = datetime.now()\n",
        "#         if timenow.minute / timeframe in slots:\n",
        "#             nextscan = timenow.replace(microsecond=0, second=0) + timedelta(minutes=timeframe)\n",
        "#             forwardscan = timenow.replace(microsecond=0, second=0) + timedelta(minutes=timeframe + 1)\n",
        "#             waitsecs = int(((forwardscan if nextscan < datetime.now() else nextscan) - datetime.now()).seconds + 30)\n",
        "#             if waitsecs > 0:\n",
        "#                 print(\"waiting {0} Seconds for Market open, Timestamp : {1} \".format(waitsecs, datetime.now()))\n",
        "#                 sleep(waitsecs)\n",
        "#             else:\n",
        "#                 sleep(0)\n",
        "\n",
        "#     while time(9, 16) <= datetime.now().time() <= time(23, 50):\n",
        "#         timenow = datetime.now()\n",
        "#         if timenow.minute / timeframe in slots:\n",
        "#             fetch_oi(symbol)\n",
        "#             dtnow = datetime.now()\n",
        "#             recentdtm = datetime(dtnow.year, dtnow.month, dtnow.day, dtnow.hour, dtnow.minute, dtnow.second)\n",
        "#             recenttime = dtnow.strftime('%H:%M')\n",
        "#             nextscan = dtnow.replace(microsecond=0, second=0) + timedelta(minutes=timeframe)\n",
        "#             print(\"nextscan\", nextscan, \"RecentScan\", recentdtm)\n",
        "#             print('Postponed Next Scan: ', nextscan < recentdtm)\n",
        "#             forwardscan = dtnow.replace(microsecond=0, second=0) + timedelta(minutes=timeframe + 1)\n",
        "#             # waitsecs = int(((forwardscan if nextscan < recentdtm or dailydata.Time[0] < recenttime else nextscan) - recentdtm).seconds)\n",
        "#             waitsecs = int(((forwardscan if nextscan < recentdtm else nextscan) - recentdtm).seconds)\n",
        "#             if waitsecs > 0:\n",
        "#                 print(\"waiting {0} Seconds next daily scan, Timestamp : {1} \".format(waitsecs, datetime.now()))\n",
        "#                 sleep(waitsecs)\n",
        "#             else:\n",
        "#                 sleep(0)\n",
        "#             print(datetime.now() - timenow, \"execution completed\")\n",
        "#         else:\n",
        "#             print(\"No Daily Dump Received\")\n",
        "#             sleep(30)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n",
        "#print(table.lower() + '_oidata_live')\n",
        "#print(indices)\n",
        "#print(def_start)\n",
        "#print(def_end)\n",
        "# new_temp_table = table.lower() + '_oidata_live'\n",
        "# print(new_temp_table)\n",
        "#update_db(new_temp_table, indices, def_start, def_end)\n",
        "\n",
        " (# update_expiry(symbol)\n",
        "# request_bod(symbol)\n",
        "# fetch_oi(symbol)\n",
        "engine = sqlite3.connect(db_file1)\n",
        "sqlite_cursor = engine.cursor()\n",
        "query = 'SELECT * FROM banknifty_oidata_live'\n",
        "sqlite_cursor.execute(query)\n",
        "output = sqlite_cursor.fetchone()\n",
        "print(output)\n",
        "sqlite_cursor.close()\n",
        "engine.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zwQVuxj9Ego"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs5x6qau9Gx_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2022 - PyAutomation - Notebook.ipynb",
      "provenance": [],
      "mount_file_id": "1uZZjl49n-qONwybACkfHSiJaJ5zIvVFx",
      "authorship_tag": "ABX9TyMmF/P3QFT6IOoorikDSsdU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}