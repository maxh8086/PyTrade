import requests
import pandas as pd
import numpy as np
import math

import pymysql
import sqlalchemy
from sqlalchemy import Table, Column, Float, Integer, String, MetaData, ForeignKey
from io import StringIO
from bs4 import BeautifulSoup

from datetime import datetime, date, timedelta
from dateutil.relativedelta import relativedelta
from time import sleep

# init all necessary variables
today = date.today()
symbol = 'BANKNIFTY'
indices = 'NIFTY BANK'
table = symbol.lower()
DBUPDATED = 0

# connect mySQL DB using sqlalchemy
engine = sqlalchemy.create_engine('mysql+pymysql://pyadmin:pyU$er#123@127.0.0.1:3306/eod_data')

# # Connect mySQL DB using pymySQL coonector
# pyconnector = pymysql.connect(host='127.0.0.1', user='pyadmin', password = "pyU$er#123", db='eod_data',)

# set date range for historical prices
start_of_year = date(today.year, 1, 1).strftime('%d-%m-%Y')
end_date = today # - timedelta(days=400) # 24-03-2021
start_date = end_date - timedelta(days=30)  # 24-03-2020

# reformat date range
def_end = end_date.strftime('%d-%b-%Y')
def_start = start_date.strftime('%d-%b-%Y')

def old_url_raw(url):
    baseurl = "https://www.nseindia.com"

    oldheader = {
        "Host": "www1.nseindia.com",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0",
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.5",
        "Accept-Encoding": "gzip, deflate, br",
        "X-Requested-With": "XMLHttpRequest",
        "Referer": "https://www1.nseindia.com/products/content/equities/indices/historical_index_data.htm",
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET,POST,PUT,DELETE,OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, Access-Control-Allow-Headers, Authorization, X-Requested-With",
        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'
        }

    try:
        output = requests.get(baseurl, headers=oldheader)
        s = requests.Session()
        output = s.get(baseurl, headers=oldheader)
        output = s.get(url, headers=oldheader)
    except ValueError:
        print(output, "error")
    return output


def get_online_db(indices = indices, sdt = def_start, edt = def_end):
    indicsurl = "https://www1.nseindia.com/products/dynaContent/equities/indices/historicalindices.jsp?indexType=" + indices + "&fromDate=" + sdt + "&toDate=" + edt
    while True:
        response = old_url_raw(indicsurl)
        if response.status_code == 200:
            page_content = BeautifulSoup(response.content, "html.parser")
            try:
                strings = page_content.find(id="csvContentDiv").get_text().replace(':', "\n")
                strings = strings.replace(' ', '')
                pdfo = pd.read_csv(StringIO(strings), header=0)
                pdfo['Open'] = pdfo['Open'].replace('-',np.nan).fillna(pdfo.Close)
                pdfo['High'] = pdfo['High'].replace('-',np.nan).fillna(pdfo.Close)
                pdfo['Low'] = pdfo['Low'].replace('-',np.nan).fillna(pdfo.Close)
                pdfo['SharesTraded'] = pdfo['SharesTraded'].replace('-','0')
                pdfo['Turnover(Rs.Cr)'] = pdfo['Turnover(Rs.Cr)'].replace('-','0')
                pdfo['Date'] = pdfo.to_datetime(pdfo['Date']).dt.strftime('%Y-%m-%d').astype(str)
                # print(df)
            except AttributeError:
                break
        else:
            response.raise_for_status()
        break
    return pdfo

        
def get_db(table = table, std = def_start, edt = def_end):
    # init required variables
    df =  pd.DataFrame()
    std = datetime.strptime(std, '%d-%b-%Y').strftime('%Y-%m-%d')
    etd = datetime.strptime(edt, '%d-%b-%Y').strftime('%Y-%m-%d')


    myQuery = '''
             SELECT * 
             FROM {0} 
             WHERE Date BETWEEN '{1}' AND '{2}' 
             ORDER BY Date DESC
             ;'''.format(table,std,etd)

    try:
        df = pd.read_sql_query(myQuery, engine)
    finally:
        return df

def update_db(indices = indices, std = def_start, edt = def_end, table = table):
    #get online data to process and update
    online = get_online_db(indices,std,edt)

    #get offline data to process and update
    offline = get_db(table,std,edt)

    merged = pd.concat([online,offline])
    merged['Date'] = pd.to_datetime(merged['Date']).dt.strftime('%Y-%m-%d').astype(str)
    merged = merged.drop_duplicates(subset=['Date'])
    merged['NaturalLog'] = np.log(merged.Close / merged.Close.shift(-1)).shift(1).fillna(0)
    merged['StdDev'] = merged['NaturalLog'].rolling(252).std().fillna(0)
    merged['W_HV'] = round(merged['StdDev'] * math.sqrt(5), 2)
    merged['M_HV'] = round(merged['StdDev'] * math.sqrt(22), 2)
    merged['Y_HV'] = round(merged['StdDev'] * math.sqrt(252), 2)
    
    # Update data to DB
    df_to_sql(merged,table)
    
def df_to_sql(df,table=table):
    # To connect MySQL database
    # Connect mySQL DB using pymySQL coonector
    pyconnector = pymysql.connect(host='127.0.0.1', user='pyadmin', password = "pyU$er#123", db='eod_data',)

    cursor = pyconnector.cursor()
    updatequery = ('''
                   ALTER TABLE {0}
                   CHANGE COLUMN `Date` `Date` DATE NOT NULL ,
                   ADD PRIMARY KEY (`Date`),
                   ADD UNIQUE INDEX `Date_UNIQUE` (`Date` ASC) VISIBLE;
                   ''').format(table)

    try:
        df.to_sql(name=table, con=engine, index=False, if_exists='replace',
                  dtype={'Date': sqlalchemy.Date(),
                         'Open': sqlalchemy.types.Float(precision=2),
                         'High': sqlalchemy.types.Float(precision=2),
                         'Low': sqlalchemy.types.Float(precision=2),
                         'Close': sqlalchemy.types.Float(precision=2),
                         'NaturalLog': sqlalchemy.types.Float(precision=6),
                         'StdDev': sqlalchemy.types.Float(precision=6),
                         'W_HV': sqlalchemy.types.Float(precision=6),
                         'M_HV': sqlalchemy.types.Float(precision=6),
                         'Y_HV': sqlalchemy.types.Float(precision=6),
                         'SharesTraded': sqlalchemy.types.Float(precision=2),
                         'Turnover(Rs.Cr)': sqlalchemy.types.Float(precision=2)
                         })
        
        # Update  / alter Database Schema to default
        cursor.execute(updatequery)
        output = pyconnector.commit()
        print('Backfill completed', output)
    
    finally:
        # To close the connection
        cursor.close()
        pyconnector.close()

def eod_backfill(indices,table=table):
    # Initialize required variables
    prices = pd.DataFrame()
    inityear = 2000
    initdate = date(inityear, 1, 1)
    year_range = relativedelta(today, initdate)

    for i in range(year_range.years):
        st1 = (date(inityear, 1, 1) + relativedelta(years=i)).strftime("%d-%m-%Y")
        ed1 = (date(inityear, 11, 30) + relativedelta(years=i)).strftime("%d-%m-%Y")
        prices = prices.append(get_online_db(indices,st1,ed1))
        st2 = (date(inityear, 12, 1) + relativedelta(years=i)).strftime("%d-%m-%Y")
        ed2 = (date(inityear, 12, 31) + relativedelta(years=i)).strftime("%d-%m-%Y")
        prices = prices.append(get_online_db(indices,st2,ed2))
        print('initiating backfill for period:', st1, ' to ', ed2)
    st3 = date(today.year, 1, 1).strftime("%d-%m-%Y")
    ed3 = today.strftime("%d-%m-%Y")
    print('initiating backfill for period:', st3, ' to ', ed3)
    prices = prices.append(get_online_db(indices,st3,ed3))
    # print(prices)
    prices['Date'] = pd.to_datetime(prices['Date']).dt.strftime('%Y-%m-%d').astype(str)
    prices = prices.drop_duplicates(subset=['Date'])
    prices['NaturalLog'] = np.log(prices.Close / prices.Close.shift(-1)).shift(1).fillna(0)
    prices['StdDev'] = prices['NaturalLog'].rolling(252).std().fillna(0)
    prices['W_HV'] = round(prices['StdDev'] * math.sqrt(5) * 100, 2 )
    prices['M_HV'] = round(prices['StdDev'] * math.sqrt(22) * 100, 2 )
    prices['Y_HV'] = round(prices['StdDev'] * math.sqrt(252) * 100, 2 )
    df_to_sql(prices,table)


def drop_table(table=table):
    # Connect mySQL DB using pymySQL coonector
    pyconnector = pymysql.connect(host='127.0.0.1', user='pyadmin', password = "pyU$er#123", db='eod_data',)
    cursor = pyconnector.cursor()
    dropquery = ('''DROP TABLE IF EXISTS {0} ;''').format(table)
    output = cursor.execute(dropquery)
    # To close the connection
    cursor.close()
    pyconnector.close()
    return output

def check_db_status():
    output = ''

    try:
        # Connect mySQL DB using pymySQL coonector
        pyconnector = pymysql.connect(host='127.0.0.1', user='pyadmin', password = "pyU$er#123", db='eod_data',)
        cursor = pyconnector.cursor()
        updatequery = ('''SELECT * FROM {0} ORDER BY Date DESC;''').format(table)
        cursor.execute(updatequery)
        output = cursor.fetchone()
    except pymysql.ProgrammingError as e:
        if (e.args[0]== 1146):
            print("Table dosen't exist, need to backfill")
            output = None
            # eod_backfill(indices,table)
    finally:
        # To close the connection
        cursor.close()
        pyconnector.close()

        if output is None:
            print('initiated complete backfill')
            eod_backfill(indices,table)
        elif output<start_of_year:
            print('Dropped old table and initiated complete backfill')
            drop_table(table)
            eod_backfill(indices,table)
        elif output<=(today- timedelta(days=30)) and output>=start_of_year:
            print('initiated full year backfill')
            beganing_year = start_of_year
            update_db(table,indices,beganing_year,def_end)
        elif output>(today- timedelta(days=30)) and output!=today and today.weekday() == 5 and output!=(today- timedelta(days=1)):
                print('initiated reguar backfill')
                update_db(table,indices,def_start,def_end)
        elif output>(today- timedelta(days=30)) and today.weekday() == 6 and output!=(today- timedelta(days=2)):
                print('initiated regular backfill')
                update_db(table,indices,def_start,def_end)
        elif output>(today- timedelta(days=30)) and today.weekday() == 0 and output!=(today- timedelta(days=3)):
                print('initiated regular backfill')
                update_db(table,indices,def_start,def_end)
        else:
            # print('Data is updated',output)
            DBUPDATED = 1

